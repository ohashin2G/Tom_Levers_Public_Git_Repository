---
title: "Studying the Age and Sex of Abalones"
author: "Group 9: Brook Assefa, Shrikant Mishra, and Tom Lever"
date: 11/25/22
output:
  pdf_document:
     extra_dependencies: "subfig"
  html_document: default
urlcolor: blue
linkcolor: red
---

# 4. A Second Question of Interest

## a. Introduction

### i. Question Statement

We conduct data analysis of the above data set towards answering the following question:

"How is the sex of male and female blacklip abalones related to and/or predicted from the number of rings / age, length, diameter, height, whole weight, shucked weight, viscera weight, and/or shell weight of the abalone?"

### ii. Value in Exploring Question

Addressing how the sex of male and female blacklip abalones is related to and/or predicted from the length, diameter, height, whole weight, shucked weight, viscera weight, and/or shell weight of abalones may be valuable in determining ways to preserve a balance of male and female abalones. Ways to promote a balance for blacklip abalone or other abalone species may be determined. Determining the success of any balance-improving or remediation program may be enhanced.

## b. Data Visualizations

### i. Data Wrangling

As this question of interest forms a binary classification problem specifying male and female as the possible responses, the data set is altered to exclude any rows that correspond to infant abalones. Essentially, the rows that contain an 'I' from the sex column are excluded.

Additionally, for logistic regression, the data must be split into a train and test set, in order to to measure potential models' effectiveness on a new data set.

```{r include=FALSE}
library(ROCR)
library(tidyverse)

set.seed(5)
```

```{r eval=TRUE, echo=FALSE, fig.align='center', fig.height=3.8, fig.width=5.3, message=FALSE, results="show"}
data <- read.csv('Data_Set--Abalone_Marine_Snails--With_Column_Names.csv')
filtered <- data %>% 
  filter(sex != 'I')
filtered$sex <- factor(filtered$sex)
sample<-sample.int(nrow(filtered), floor(.50*nrow(filtered)), replace = F)
train <- filtered[sample, ]
test <- filtered[-sample, ]
```

### ii - iii. Presentation and Interpretation of Data Visualizations

With the training data created, the first step is to perform exploratory data analysis to understand any potential patterns within the data.

Both a frequency table and a proportions table comparing data counts between male and female abalones are depicted below. There are slightly more male abalones in our training data set, but there is sufficient representation for both values of our binary response variable.

```{r, eval=TRUE, echo=FALSE, results="show", message=FALSE, fig.width = 5.3, fig.height = 3.8, fig.align='center', fig.subcap=c(1, 2), fig.ncol = 2}
table(train$sex)
```

```{r echo=FALSE}
prop.table(table(train$sex))
```

By comparing boxplots of the physical attributes (e.g. length, shucked weight), any differences between the distributions of these attributes can be assessed between male and female abalones. These boxplots are presented in the figure below.

```{r fig.align='center', fig.height=3.8, fig.width=5.3, message=FALSE, include=FALSE, results="show"}
library(gridExtra)
#https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html
l <- ggplot(train, aes(x = sex, y = length)) +
  geom_boxplot(fill = "Blue", color = "Orange")
d <- ggplot(train, aes(x = sex, y = diameter)) +
  geom_boxplot(fill = "Blue", color = "Orange")
h <- ggplot(train, aes(x = sex, y = height)) +
  geom_boxplot(fill = "Blue", color = "Orange")
ww <- ggplot(train, aes(x = sex, y = whole_weight)) +
  geom_boxplot(fill = "Blue", color = "Orange")
sw1 <- ggplot(train, aes(x = sex, y = shucked_weight)) +
  geom_boxplot(fill = "Blue", color = "Orange")
sw2 <- ggplot(train, aes(x = sex, y = shell_weight)) +
  geom_boxplot(fill = "Blue", color = "Orange")
r <- ggplot(train, aes(x = sex, y = rings)) +
  geom_boxplot(fill = "Blue", color = "Orange")
```

```{r, eval=TRUE, echo=FALSE, results="show", message=FALSE, fig.width = 5.3, fig.height = 3.8, fig.align='center', fig.cap="Boxplots comparing the distribution of the seven predictor variables between male and female abalones"}
grid.arrange(l, d, h, ww, sw1, sw2, r)
```

It appears that the distributions of the physical attributes do not greatly differ when comparing between male and female abalones. However, it does appear that for several variables, male abalones tend to have slightly lower distribution. Male blacklip abalones have more outliers on the lower half, as seen with length and diameter. Males have a slightly lower minimum, first quartile, median, third quartile, and maximum for the vast majority of these plots. Although there is nothing conclusive in the figure, male blacklip abalones may be smaller than female blacklip abalones. A binary classifier may be able to detect this trend.

Next, depicted below are multivariate plots comparing blacklip abalone physical attributes against one another, with the color of the data point indicating the abalone's sex. This is done to assess whether a potential pattern can be seen that separates the two groups on a scatter plot between the predictors. Multiple plots were observed during exploratory data analysis, and the following six best represent the relationships between variables.

```{r fig.align='center', fig.height=3.8, fig.width=5.3, message=FALSE, include=FALSE, results="show"}
library(gridExtra)
#https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html
l1 <- ggplot(filtered, aes(x = length, y = diameter, color = sex)) +
  geom_point(alpha = 0.5)
l2 <- ggplot(filtered, aes(x = length, y = height, color = sex)) +
  geom_point(alpha = 0.5)
l3<-ggplot(filtered, aes(x = shell_weight, y = shucked_weight, color = sex)) +
  geom_point(alpha = 0.5)
l4<-ggplot(filtered, aes(x = height, y = whole_weight, color = sex)) +
  geom_point(alpha = 0.5)
l5<-ggplot(filtered, aes(x = diameter, y = viscera_weight, color = sex)) +
  geom_point(alpha = 0.5)
l6<-ggplot(filtered, aes(x = whole_weight, y = rings, color = sex)) +
  geom_point(alpha = 0.5)
```

```{r, eval=TRUE, echo=FALSE, results="show", message=FALSE, fig.width = 5.3, fig.height = 3.8, fig.align='center', fig.cap = "Multivariable scatter plots comparing blacklip abalone physical attributes against one another"}
grid.arrange(l1, l2, l3, l4, l5, l6)
```

It can be seen that male and female data points appear to be interspersed throughout the graphs. However, the male data points also appear to occupy more of the lower ranges of both axes in each plot. More blue points exist in the bottom-left region, where length ranges from 0 - 0.4 mm.

Thus, we can state that although we can see some very slight differences that could distinguish male and female abalones apart, there is nothing conclusive in our preliminary data visualizations. We are unsure that a logistic regression model will be able to accurately predict an abalone's sex based off of its physical attributes.

## c. Model Building

### ii. Choice of Initial Logistic Regression Model

Our second question of interest is framed in a way that we want to understand the true relationship between the predictor variables and the sex variable, as well as to predict and extrapolate on new data. Thus, for our initial model, we will keep all variables present as a baseline, but we will try to improve on this model in the section below.

The general form of this initial model, Model 0, can be described as: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1} \ length  + \hat{\beta_2} \ diameter + \hat{\beta_3} \ height + \hat{\beta_4} \ whole + \hat{\beta_5} \ shucked +\hat{\beta_6} \ viscera + \hat{\beta_7} \ shell + \hat{\beta_8} \ rings$$

```{r include=FALSE}
full_model <- glm(sex~., family = "binomial", data = train)
```

Fitting this model to the training data using the "glm" command in R, the initial regression model has an equation of:

$$\begin{aligned}
    log \frac{\hat{\pi}}{1-\hat{\pi}} & = 2.57043 \\ 
                                      & + 0.73048 \ length \\
                                      & -7.49341 \ diameter \\
                                      & -2.59351 \ height \\
                                      & -0.11939 \ whole \\
                                      & + 2.92424 \ shucked \\
                                      & -2.97086 \ viscera \\
                                      & + 1.14699 \ shell \\
                                      & + 0.00696 \ rings 
\end{aligned}$$

A hypothesis test is performed below to confirm whether this initial model is useful in predicting the log odds of the sex variable:

$H_0: \beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = \beta_6 = \beta_7 = \beta_8 = 0$

$H_a:$ At least one of the coefficients in $H_0$ is not 0.

To perform this test, the $\Delta G^2$ statistic is calculated by getting the difference between the deviance of an intercept-only model and our full model, which is 37.23. Comparing this value to a $\chi^2$ distribution with 8 degrees of freedom, we calculate a p-value of $1.0456 \times 10^{-6}$.

```{r include=FALSE}
deltaG2 <- full_model$null.deviance - full_model$deviance
deltaG2
```

```{r include=FALSE}
1-pchisq(deltaG2, 8)
```

Since the p-value is less than $\alpha$ = 0.05, we reject $H_0$. There is sufficient evidence that our initial model is useful in predicting the log odds of abalones' sex.

### ii. Improvements to Initial Model

We analyze the correlation matrix between predictors, in order to check for evidence of multicollinearity:

```{r}
cor(train[, c(-1)])
```

This matrix shows that there are indeed high correlations between all the predictors in regards to one another, with the exception of $rings$. In fact, $rings$ is the only variable that does not have high or very high correlation with the other predictors.

To further receive evidence for multicollinearity in the model, VIFs in the model are calculated below:

```{r include=FALSE}
library(faraway)
```

```{r echo=FALSE}
vif(full_model)
```

The VIF values for all predictors can be considered high (greater than 10), with the exception of rings, so we can conclude that the model has multicollinearity. This may not have been a significant issue if the model was exclusively built for prediction, but question 2 aims to understand the true relationship between these variables and abalone's sex, as well as to be able to extrapolate with new data. For these reasons, this will require reducing multicollinearity as much as possible.

Intuitively, through the description of the data set being used, we know that whole weight, shucked weight, viscera weight, and shell weight are most likely linked because they all represent similar attributes. While shucked weight, viscera weight, and shell weight represent the weights of individual components of an abalone, whole weight represents the entire weight combined. It makes sense that a larger value for one would also mean a larger value for another, hence the very high positive correlation between them.

Similarly, length and diameter are highly correlated (.978) because they are just perpendicular measurements of the shell on the same plane. Height is not considered along with these two for now, as length and diameter are horizontal measurements pertaining to the abalone's shell, while height is a vertical measurement that includes soft tissue as well.

For each of these two groups (whole weight, shucked weight, shell weight and length, diameter), we can choose one variable to represent the group within a model with reduced parameters.

Using combinations of the choices of predictors in both groups, we now have a potential set of eight 4-predictor models. Because high correlation exists between predictors across groups as well (e.g. length and whole_weight, diameter and viscera weight), we will add 7 two-predictor models, with rings as one predictor and a choice of one out of the remaining 7. It may make sense that a longer abalone may also have a higher weight. Rings is kept in all models, because it has a low to medium correlation with other variables.

Compiling all of these together, we have a set of 15 potential logistic regression models that could help describe the relationship between the the physical attributes of a blacklip abalone and its sex:

Model 1: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1}length  + \hat{\beta_3}height + \hat{\beta_4}whole + \hat{\beta_8}rings$$

Model 2: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1}length  + \hat{\beta_3}height + \hat{\beta_5}shucked + \hat{\beta_8}rings$$

Model 3: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1}length  + \hat{\beta_3}height + \hat{\beta_6}viscera + \hat{\beta_8}rings$$

Model 4: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1}length  + \hat{\beta_3}height + \hat{\beta_7}shell + \hat{\beta_8}rings$$

Model 5: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_2}diameter  + \hat{\beta_3}height + \hat{\beta_4}whole + \hat{\beta_8}rings$$

Model 6: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_2}diameter  + \hat{\beta_3}height + \hat{\beta_5}shucked + \hat{\beta_8}rings$$

Model 7:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_2}diameter  + \hat{\beta_3}height + \hat{\beta_6}viscera + \hat{\beta_8}rings$$

Model 8:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_2}diameter  + \hat{\beta_3}height + \hat{\beta_7}shell + \hat{\beta_8}rings$$

Model 9:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1}length  + \hat{\beta_8}rings$$

Model 10:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_2}diameter  + \hat{\beta_8}rings$$

Model 11:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_3}height  + \hat{\beta_8}rings$$

Model 12:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_4}whole  + \hat{\beta_8}rings$$

Model 13:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_5}shucked  + \hat{\beta_8}rings$$

Model 14:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_6}viscera  + \hat{\beta_8}rings$$

Model 15:$$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_7}shell  + \hat{\beta_8}rings$$

```{r include=FALSE}
reduced1 <- glm(sex~length + height + whole_weight + rings, family = "binomial", data = train)
reduced2 <- glm(sex~length + height + shucked_weight + rings, family = "binomial", data = train)
reduced3 <- glm(sex~length + height + viscera_weight + rings, family = "binomial", data = train)
reduced4 <- glm(sex~length + height + shell_weight + rings, family = "binomial", data = train)

reduced5 <- glm(sex~diameter + height + whole_weight + rings, family = "binomial", data = train)
reduced6 <- glm(sex~diameter + height + shucked_weight + rings, family = "binomial", data = train)
reduced7 <- glm(sex~diameter + height + viscera_weight + rings, family = "binomial", data = train)
reduced8 <- glm(sex~diameter + height + shell_weight + rings, family = "binomial", data = train)

reduced9 <- glm(sex~length + rings, family = "binomial", data = train)
reduced10 <- glm(sex~diameter + rings, family = "binomial", data = train)
reduced11 <- glm(sex~height + rings, family = "binomial", data = train)
reduced12 <- glm(sex~whole_weight + rings, family = "binomial", data = train)
reduced13 <- glm(sex~shucked_weight + rings, family = "binomial", data = train)
reduced14 <- glm(sex~viscera_weight + rings, family = "binomial", data = train)
reduced15 <- glm(sex~shell_weight + rings, family = "binomial", data = train)
```

### iii. Performance of Model

Figure **num** shows the generated ROC curves for each of the models listed above. The results from these plots are not promising, as the ROC curve for all of the models appear to be close to the diagonal. While the curves of Model 2 and Model 6 appear to be further away from the diagonal, it is not by a significant margin. Thus, in general, these plots indicate that our models are not much better than random guessing.

```{r echo=FALSE, fig.cap='ROC curves of all potential models', fig.ncol=4, out.width="25%", fig.subcap=c('Full Model 0', 'Reduced Model 1', 'Reduced Model 2', 'Reduced Model 3', 'Reduced Model 4', 'Reduced Model 5', 'Reduced Model 6', 'Reduced Model 7', 'Reduced Model 8', 'Reduced Model 9', 'Reduced Model 10', 'Reduced Model 11', 'Reduced Model 12', 'Reduced Model 13', 'Reduced Model 14', 'Reduced Model 15')}
#https://bookdown.org/yihui/rmarkdown-cookbook/latex-subfigure.html
library(ROCR)
preds_full <- predict(full_model, newdata = test, type = "response")
rates_full <- prediction(preds_full, test$sex)
roc_full <- performance(rates_full, measure = "tpr", x.measure = "fpr")
plot(roc_full, main = "ROC Curve for Model 0")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced1 <- predict(reduced1, newdata = test, type = "response")
rates_reduced1 <- prediction(preds_reduced1, test$sex)
roc_reduced1 <- performance(rates_reduced1, measure = "tpr", x.measure = "fpr")
plot(roc_reduced1, main = "ROC Curve for Model 1")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced2 <- predict(reduced2, newdata = test, type = "response")
rates_reduced2 <- prediction(preds_reduced2, test$sex)
roc_reduced2 <- performance(rates_reduced2, measure = "tpr", x.measure = "fpr")
plot(roc_reduced2, main = "ROC Curve for Model 2")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced3 <- predict(reduced3, newdata = test, type = "response")
rates_reduced3 <- prediction(preds_reduced3, test$sex)
roc_reduced3 <- performance(rates_reduced3, measure = "tpr", x.measure = "fpr")
plot(roc_reduced3, main = "ROC Curve for Model 3")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced4 <- predict(reduced4, newdata = test, type = "response")
rates_reduced4 <- prediction(preds_reduced4, test$sex)
roc_reduced4 <- performance(rates_reduced4, measure = "tpr", x.measure = "fpr")
plot(roc_reduced4, main = "ROC Curve for Model 4")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced5 <- predict(reduced5, newdata = test, type = "response")
rates_reduced5 <- prediction(preds_reduced5, test$sex)
roc_reduced5 <- performance(rates_reduced5, measure = "tpr", x.measure = "fpr")
plot(roc_reduced5, main = "ROC Curve for Model 5")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced6 <- predict(reduced6, newdata = test, type = "response")
rates_reduced6 <- prediction(preds_reduced6, test$sex)
roc_reduced6 <- performance(rates_reduced6, measure = "tpr", x.measure = "fpr")
plot(roc_reduced6, main = "ROC Curve for Model 6")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced7 <- predict(reduced7, newdata = test, type = "response")
rates_reduced7 <- prediction(preds_reduced7, test$sex)
roc_reduced7 <- performance(rates_reduced7, measure = "tpr", x.measure = "fpr")
plot(roc_reduced7, main = "ROC Curve for Model 7")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced8 <- predict(reduced8, newdata = test, type = "response")
rates_reduced8 <- prediction(preds_reduced8, test$sex)
roc_reduced8 <- performance(rates_reduced8, measure = "tpr", x.measure = "fpr")
plot(roc_reduced8, main = "ROC Curve for Model 8")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced9 <- predict(reduced9, newdata = test, type = "response")
rates_reduced9 <- prediction(preds_reduced9, test$sex)
roc_reduced9 <- performance(rates_reduced9, measure = "tpr", x.measure = "fpr")
plot(roc_reduced9, main = "ROC Curve for Model 9")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced10 <- predict(reduced10, newdata = test, type = "response")
rates_reduced10 <- prediction(preds_reduced10, test$sex)
roc_reduced10 <- performance(rates_reduced10, measure = "tpr", x.measure = "fpr")
plot(roc_reduced10, main = "ROC Curve for Model 10")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced11 <- predict(reduced11, newdata = test, type = "response")
rates_reduced11 <- prediction(preds_reduced11, test$sex)
roc_reduced11 <- performance(rates_reduced11, measure = "tpr", x.measure = "fpr")
plot(roc_reduced11, main = "ROC Curve for Model 11")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced12 <- predict(reduced12, newdata = test, type = "response")
rates_reduced12 <- prediction(preds_reduced12, test$sex)
roc_reduced12 <- performance(rates_reduced12, measure = "tpr", x.measure = "fpr")
plot(roc_reduced12, main = "ROC Curve for Model 12")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced13 <- predict(reduced13, newdata = test, type = "response")
rates_reduced13 <- prediction(preds_reduced13, test$sex)
roc_reduced13 <- performance(rates_reduced13, measure = "tpr", x.measure = "fpr")
plot(roc_reduced13, main = "ROC Curve for Model 13")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced14 <- predict(reduced14, newdata = test, type = "response")
rates_reduced14 <- prediction(preds_reduced14, test$sex)
roc_reduced14 <- performance(rates_reduced14, measure = "tpr", x.measure = "fpr")
plot(roc_reduced14, main = "ROC Curve for Model 14")
lines(x = c(0, 1), y = c(0, 1), col = "red")

preds_reduced15 <- predict(reduced15, newdata = test, type = "response")
rates_reduced15 <- prediction(preds_reduced15, test$sex)
roc_reduced15 <- performance(rates_reduced15, measure = "tpr", x.measure = "fpr")
plot(roc_reduced15, main = "ROC Curve for Model 15")
lines(x = c(0, 1), y = c(0, 1), col = "red")
```

```{r include=FALSE}
auc_full <- performance(rates_full, measure = "auc")
auc_reduced1 <- performance(rates_reduced1, measure = "auc")
auc_reduced2 <- performance(rates_reduced2, measure = "auc")
auc_reduced3 <- performance(rates_reduced3, measure = "auc")
auc_reduced4 <- performance(rates_reduced4, measure = "auc")
auc_reduced5 <- performance(rates_reduced5, measure = "auc")
auc_reduced6 <- performance(rates_reduced6, measure = "auc")
auc_reduced7 <- performance(rates_reduced7, measure = "auc")
auc_reduced8 <- performance(rates_reduced8, measure = "auc")
auc_reduced9 <- performance(rates_reduced9, measure = "auc")
auc_reduced10 <- performance(rates_reduced10, measure = "auc")
auc_reduced11 <- performance(rates_reduced11, measure = "auc")
auc_reduced12 <- performance(rates_reduced12, measure = "auc")
auc_reduced13 <- performance(rates_reduced13, measure = "auc")
auc_reduced14 <- performance(rates_reduced14, measure = "auc")
auc_reduced15 <- performance(rates_reduced15, measure = "auc")
```

The table below ranks the fifteen models by their area under the ROC curve (AUC) values. As seen with the plots in figure **num**, model 2 is the best performing model with an AUC value of 0.58. However, the margin between model 2 and the lowest performing model, Model 15, is only approximately 0.04.

```{r include=FALSE}
auc_reduced_models<-c(auc_full@y.values[[1]], auc_reduced1@y.values[[1]], auc_reduced2@y.values[[1]], auc_reduced3@y.values[[1]], auc_reduced4@y.values[[1]], auc_reduced5@y.values[[1]], auc_reduced6@y.values[[1]], auc_reduced7@y.values[[1]], auc_reduced8@y.values[[1]], auc_reduced9@y.values[[1]], auc_reduced10@y.values[[1]], auc_reduced11@y.values[[1]], auc_reduced12@y.values[[1]], auc_reduced13@y.values[[1]], auc_reduced14@y.values[[1]], auc_reduced15@y.values[[1]])

model_names <- c('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15')
auc_sorted <- data.frame(model_names, auc_reduced_models)
auc_sorted <- auc_sorted %>% 
  arrange(desc(auc_reduced_models))
#auc_sorted
```

| Model |    AUC    |
|:-----:|:---------:|
|   2   | 0.5808754 |
|   0   | 0.5771254 |
|   6   | 0.5749740 |
|   1   | 0.5656410 |
|   5   | 0.5612851 |
|  11   | 0.5553576 |
|  15   | 0.5528716 |
|  14   | 0.5490835 |
|   3   | 0.5472616 |
|  12   | 0.5470613 |
|   4   | 0.5460276 |
|  13   | 0.5457913 |
|   7   | 0.5438141 |
|   9   | 0.5437921 |
|  10   | 0.5435407 |
|   8   | 0.5429768 |

: Potential models ranked by AUC

```{r include=FALSE}
cm_full <- table(test$sex, preds_full>0.5)
err_full <- (cm_full[1, 2] + cm_full[2, 1])/(sum(cm_full))

cm_reduced1 <- table(test$sex, preds_reduced1>0.5)
err_reduced1 <- (cm_reduced1[1, 2] + cm_reduced1[2, 1])/(sum(cm_reduced1))

cm_reduced2 <- table(test$sex, preds_reduced2>0.5)
err_reduced2 <- (cm_reduced2[1, 2] + cm_reduced2[2, 1])/(sum(cm_reduced2))

cm_reduced3 <- table(test$sex, preds_reduced3>0.5)
err_reduced3 <- (cm_reduced3[1, 2] + cm_reduced3[2, 1])/(sum(cm_reduced3))

cm_reduced4 <- table(test$sex, preds_reduced4>0.5)
err_reduced4 <- (cm_reduced4[1, 2] + cm_reduced4[2, 1])/(sum(cm_reduced4))

cm_reduced5 <- table(test$sex, preds_reduced5>0.5)
err_reduced5 <- (cm_reduced5[1, 2] + cm_reduced5[2, 1])/(sum(cm_reduced5))

cm_reduced6 <- table(test$sex, preds_reduced6>0.5)
err_reduced6 <- (cm_reduced6[1, 2] + cm_reduced6[2, 1])/(sum(cm_reduced6))

cm_reduced7 <- table(test$sex, preds_reduced7>0.5)
err_reduced7 <- (cm_reduced7[1, 2] + cm_reduced7[2, 1])/(sum(cm_reduced7))

cm_reduced8 <- table(test$sex, preds_reduced8>0.5)
err_reduced8 <- (cm_reduced8[1, 2] + cm_reduced8[2, 1])/(sum(cm_reduced8))

cm_reduced9 <- table(test$sex, preds_reduced9>0.5)
err_reduced9 <- (cm_reduced9[1, 2] + cm_reduced9[2, 1])/(sum(cm_reduced9))

cm_reduced10 <- table(test$sex, preds_reduced10>0.5)
err_reduced10 <- (cm_reduced10[1, 2] + cm_reduced10[2, 1])/(sum(cm_reduced10))

cm_reduced11 <- table(test$sex, preds_reduced11>0.5)
err_reduced11 <- (cm_reduced11[1, 2] + cm_reduced11[2, 1])/(sum(cm_reduced11))

cm_reduced12 <- table(test$sex, preds_reduced12>0.5)
err_reduced12 <- (cm_reduced12[1, 2] + cm_reduced12[2, 1])/(sum(cm_reduced12))

cm_reduced13 <- table(test$sex, preds_reduced13>0.5)
err_reduced13 <- (cm_reduced13[1, 2] + cm_reduced13[2, 1])/(sum(cm_reduced13))

cm_reduced14 <- table(test$sex, preds_reduced14>0.5)
err_reduced14 <- (cm_reduced14[1, 2] + cm_reduced14[2, 1])/(sum(cm_reduced14))

cm_reduced15 <- table(test$sex, preds_reduced15>0.5)
err_reduced15 <- (cm_reduced15[1, 2] + cm_reduced15[2, 1])/(sum(cm_reduced15))

#cm_reduced15
```

In the figure below, we rank the potential models by their error rate. A threshold of 0.5 was chosen for the confusion matrix from which the error rate is calculated, because we are only interested in the lowest error rate rather than trying to limit false positive or false negative rates.

```{r include=FALSE}
err_reduced_models<-c(err_full, err_reduced1, err_reduced2, err_reduced3,err_reduced4, err_reduced5, err_reduced6,err_reduced7, err_reduced8, err_reduced9,err_reduced10, err_reduced11, err_reduced12,err_reduced13, err_reduced14, err_reduced15)

model_names <- c('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15')
err_sorted <- data.frame(model_names, err_reduced_models)
err_sorted <- err_sorted %>% 
  arrange(err_reduced_models)
#err_sorted
```

| Model | Error Rate |
|:-----:|:----------:|
|   2   | 0.4393512  |
|   0   | 0.4400564  |
|   6   | 0.4407616  |
|   1   | 0.4485190  |
|   5   | 0.4492243  |
|   8   | 0.4569817  |
|   9   | 0.4583921  |
|   3   | 0.4598025  |
|  11   | 0.4612130  |
|  10   | 0.4619182  |
|   7   | 0.4640339  |
|   4   | 0.4654443  |
|  15   | 0.4675599  |
|  14   | 0.4682652  |
|  12   | 0.4724965  |
|  13   | 0.4851904  |

: Potential models ranked by error rate

The model with the lowest error rate is model 2, with an error rate of 0.439. Additionally, the error rates range from 0.439 to 0.485, which again reinforces that the performance between the best and worst models is not drastically different. Again, similar to the AUC results, model 2's error value indicates that while it might be marginally better than the rest, the model does not perform well on the test data set.

### iv. Recommended Model

With its performance in regards to e would like to recommend model 2. Model 2 marginally performs the best out of all models in regards to AUC and error rate, even outperforming the full model.

The general form of the model: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = \hat{\beta_0} + \hat{\beta_1}length  + \hat{\beta_3}height + \hat{\beta_5}shucked + \hat{\beta_8}rings$$ The model fitted to the training data: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = 2.808184 -5.281277 \ length - 3.840513 \ height + 2.080794 \ shucked + 0.003041 \ rings$$

A hypothesis test is performed below to compare Model 2 to Model 0, the initial model:

$H_0: \beta_2 = \beta_4 = \beta_6 = \beta_7 = 0$

$H_a:$ At least one of the coefficients in $H_0$ is not 0.

To perform this test, the $\Delta G^2$ statistic is calculated by getting the difference between the deviance of Model 2 and the full model, which is 8.70. Comparing this value to a $\chi^2$ distribution with 4 degrees of freedom, we calculate a p-value of $0.069$.

```{r include=FALSE}
deltaG2 <- reduced2$deviance - full_model$deviance
deltaG2
```

```{r include=FALSE}
1-pchisq(deltaG2, 4)
```

Since the p-value is not less than $\alpha$ = 0.05, we fail to reject $H_0$. Thus, we go with the 4-predictor model (Model 2) over the full model (Model 0) when predicting the log odds of abalones' sex.

With all that said, the low AUC values and high error rates show that this model is not ideal in predicting the log odds of abalone's sex.

Additionally, below are the VIF values for the $length$, &height&, $shucked_weight$, and $rings$ predictors:

```{r echo=FALSE}
vif(reduced2)
```

Aside from $rings$, these VIF values are still above 10, which indicates multicollinearity and further reinforces that while this model performs marginally better than the others, it is not ideal.

## d. Conclusions

### i. Addressing Question of Interest

Our question of interest propelled us to investigate whether a relationship between any or all physical attributes of an abalone and the abalone's sex could be established, or whether knowing the measurements for the former could help us predict the latter.

The final model that was decided upon was: $$log \frac{\hat{\pi}}{1-\hat{\pi}} = 2.808184 -5.281277 \ length - 3.840513 \ height + 2.080794 \ shucked + 0.003041 \ rings$$

While it outperformed the other fifteen models by having the highest Area Under ROC Curve value (0.581) and the lowest error rate (0.439), these values along with an ROC Curve that is close to the diagonal indicate that this model is not able to accurately predict log-odds of sex, and unable to accurately represent the relationship between the physical attributes of an abalone and its sex.

The range between the best and worst models for AUC was 0.034, and the range between the best and worst models for error rate was 0.023. This indicates that these models did not differ much regardless of choice of predictors, and were equally bad at predicting blacklip abalones' sex.

Thus, we say that question 2 was not answered by the chosen model, and cannot be answered by similar logistic regression models using the provided data. This reinforces the results of the exploratory data analysis conducted beforehand, where there weren't clear difference between male and female abalones across the various plots.

### ii. Insights

*Provide interesting insights.*

### iii. Challenges

The largest challenge for the group with this question was ensuring that all decisions taken during the initial model improvement steps were valid. We were very curious whether components of our analysis from the linear regression section, such as multicollinearity, stepwise regression, and certain hypothesis testing would still be relevant if used when performing logistic regression. This also included making sure the decision to reduce the number of parameters for potential models based on context from the data description, such as reducing the number of weight variables due to their high correlation and underlying relationship, was also valid.
