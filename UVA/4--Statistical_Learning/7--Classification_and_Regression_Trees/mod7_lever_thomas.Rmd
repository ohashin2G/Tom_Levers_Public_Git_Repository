---
title: "DS-6030 Homework Module 7"
author: "Tom Lever"
date: 07/08/2023
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---

<!--- Below are global settings for knitr. You can override any of them by adding the changes to individual chunks --->
```{r global_options, include = FALSE}
# This chunk is called global_options. Due to `include = FALSE`, when the document is rendered, the chunk will be executed, but the results and code will not be included in the rendered document
knitr::opts_chunk$set(
    error = TRUE, # Keep compiling upon error
    collapse = FALSE, # code and corresponding output appear in knit file in separate blocks
    echo = TRUE, # echo code by default
    comment = "#", # change comment character
    #fig.width = 5.5, # set figure width
    fig.align = "center", # set figure position
    #out.width = "49%", # set width of displayed images
    warning = TRUE, # do not show R warnings
    message = TRUE # do not show R messages
)
```

**DS 6030 | Spring 2023 | University of Virginia **

8.  In the lab, a classification tree was applied to the Carseats data set after converting Sales into a qualitative response variable. 

    Now we will seek to predict Sales using regression trees and related approaches, treating the response as a quantitative variable.

    (a) Split the data set into a training set and a test set.
    
        ```{r}
        set.seed(1)
        library(ISLR2)
        library(TomLeversRPackage)
        training_and_testing_data <- split_data_set_into_training_and_testing_data(
            Carseats,
            proportion_of_training_data = 0.9
        )
        training_data <- training_and_testing_data$training_data
        testing_data <- training_and_testing_data$testing_data
        head(training_data, n = 2)
        head(testing_data, n = 2)
        ```

    (b) Fit a regression tree to the training set. Plot the tree, and interpret the results. What test MSE do you obtain?
    
        ```{r, fig.height = 10, fig.width = 14}
        library(tree)
        full_tree <- tree(Sales ~ ., data = training_data)
        summary(full_tree)
        plot(full_tree)
        text(full_tree, pretty = 0)
        vector_of_predicted_sales <- predict(full_tree, newdata = testing_data)
        vector_of_actual_sales <- testing_data$Sales
        calculate_mean_squared_error(vector_of_predicted_sales, vector_of_actual_sales)
        ```
        
        When shelf location is good and price is less than $109.5$ monetary units, our tree predicts that 12.190 thousand child car seats will be sold at each location in each time period.
        
        The test Mean Squared Error of our tree when predicting sales is $4.896 \ thousand^2$.

    (c) Use cross-validation in order to determine the optimal level of tree complexity. Does pruning the tree improve the test MSE?
    
        ```{r}
        object_of_types_prune_and_tree_sequence <- cv.tree(full_tree)
        vector_of_numbers_of_leaves <- object_of_types_prune_and_tree_sequence$size
        vector_of_deviances <- object_of_types_prune_and_tree_sequence$dev
        plot(vector_of_numbers_of_leaves, vector_of_deviances, type = "l")
        index_of_minimum_deviance <- which.min(vector_of_deviances)
        optimal_number_of_leaves <-
            vector_of_numbers_of_leaves[index_of_minimum_deviance]
        minimum_deviance <- min(vector_of_deviances)
        points(
            optimal_number_of_leaves,
            minimum_deviance,
            col = "red",
            cex = 2,
            pch = 20
        )
        pruned_tree <- prune.tree(full_tree, best = optimal_number_of_leaves)
        plot(pruned_tree)
        text(pruned_tree, pretty = 0)
        vector_of_predicted_sales <- predict(pruned_tree, newdata = testing_data)
        calculate_mean_squared_error(vector_of_predicted_sales, vector_of_actual_sales)
        ```
        
        The test Mean Squared Error for the pruned tree is greater and less desirable than the Mean Squared Error for the full tree.

    (d) Use the bagging approach in order to analyze this data. What test MSE do you obtain? Use the `importance()` function to determine which variables are most important.
    
        Per *An Introduction to Statistical Learning* (Second Edition), bagging "is simply a special case of a random forest with [the number of variables randomly sampled as candidates at each split] $m = p$ the number of predictors." 
    
        ```{r}
        library(randomForest)
        index_of_column_Sales <-
            get_index_of_column_of_data_frame(training_data, "Sales")
        data_frame_of_predictors <- training_data[, -index_of_column_Sales]
        data_frame_of_sales <- training_data[, index_of_column_Sales]
        number_of_predictors <- ncol(data_frame_of_predictors)
        get_test_MSE_and_vector_of_ordered_percents_increase_in_MSE_for_random_forest <-
            function(mtry) {
            the_randomForest <- randomForest(
                formula = Sales ~ .,
                data = training_data,
                mtry = mtry,
                importance = TRUE
            )
            vector_of_predicted_sales <-
                predict(the_randomForest, newdata = testing_data)
            test_MSE <- calculate_mean_squared_error(
                vector_of_predicted_sales,
                vector_of_actual_sales
            )
            matrix_of_importance_metrics <- importance(the_randomForest)
            vector_of_percents_increase_in_MSE <-
               matrix_of_importance_metrics[, "%IncMSE"]
            vector_of_indices_of_ordered_percents_increase_in_MSE <-
                order(vector_of_percents_increase_in_MSE, decreasing = TRUE)
            vector_of_ordered_percents_increase_in_MSE <- 
                vector_of_percents_increase_in_MSE[
                    vector_of_indices_of_ordered_percents_increase_in_MSE
                ]
            list_of_test_MSE_and_vector_of_ordered_percents_increase_in_MSE_for_random_forest <-
                list(
                    test_MSE = test_MSE,
                    vector_of_ordered_percents_increase_in_MSE =
                        vector_of_ordered_percents_increase_in_MSE
                )
            return(
                list_of_test_MSE_and_vector_of_ordered_percents_increase_in_MSE_for_random_forest
            )
        }
        get_test_MSE_and_vector_of_ordered_percents_increase_in_MSE_for_random_forest(
            mtry = number_of_predictors
        )
        ```
        
        The test Mean Squared Error for our bootstrap aggregation (BAg) is $2.974$, which is $0.607$ of the MSE for our full tree and $0.438$ of the MSE for our pruned tree.
        
        According to [In a random forest, is larger %IncMSE better or worse?](https://stats.stackexchange.com/questions/162465/in-a-random-forest-is-larger-incmse-better-or-worse), "%IncMSE is the most robust and informative measure. IT is the increase in mse of predictions(estimated with out-of-bag-CV) as a result of variable j being permuted(values randomly shuffled)... the higher the number, the more important."
        
        $\%IncMSE$ is highest for $ShelveLoc$ followed by $Price$; $ShelveLoc$ and $Price$ are the two most important variables.

    (e) Use random forests to analyze this data. What test MSE do you obtain? Use the `importance()` function to determine which variables are most important. Describe the effect of m, the number of variables considered at each split, on the error rate obtained.
    
        ```{r}
        data_frame_of_values_of_mtry_and_test_MSEs <- data.frame(
            matrix(NA, nrow = number_of_predictors, ncol = 2)
        )
        colnames(data_frame_of_values_of_mtry_and_test_MSEs) <- c("mtry", "test_MSE")
        for (mtry in 1:number_of_predictors) {
            print(paste("mtry: ", mtry, sep = ""))
            data_frame_of_values_of_mtry_and_test_MSEs[mtry, "mtry"] <- mtry
            test_MSE_and_vector_of_ordered_percents_increase_in_MSE <- 
                get_test_MSE_and_vector_of_ordered_percents_increase_in_MSE_for_random_forest(
                    mtry = mtry
                )
            test_MSE <- test_MSE_and_vector_of_ordered_percents_increase_in_MSE$test_MSE
            vector_of_ordered_percents_increase_in_MSE <-
                test_MSE_and_vector_of_ordered_percents_increase_in_MSE$
                    vector_of_ordered_percents_increase_in_MSE
            print(vector_of_ordered_percents_increase_in_MSE)
            data_frame_of_values_of_mtry_and_test_MSEs[mtry, "test_MSE"] <- test_MSE
        }
        print(data_frame_of_values_of_mtry_and_test_MSEs)
        vector_of_values_of_mtry <- data_frame_of_values_of_mtry_and_test_MSEs$mtry
        vector_of_test_MSEs <- data_frame_of_values_of_mtry_and_test_MSEs$test_MSE
        plot(
            x = vector_of_values_of_mtry,
            y = vector_of_test_MSEs,
            type = "l"
        )
        index_of_minimum_test_MSE <- which.min(vector_of_test_MSEs)
        optimal_value_of_mtry <-
            vector_of_values_of_mtry[index_of_minimum_test_MSE]
        minimum_test_MSE <- min(vector_of_test_MSEs)
        points(
            optimal_value_of_mtry,
            minimum_test_MSE,
            col = "red",
            cex = 2,
            pch = 20
        )
        ```
        
        See above plot for test Mean Squared Errors for different values of the number of variables randomly sampled as candidates at each split $m$. Test MSE decreases parabolically with number of variables to a minimum for $m = 8$. In all cases $ShelveLoc$ and $Price$ are the most important predictors.

    (f) Now analyze the data using BART, and report your results. (skip this exercise)

9.  This problem involves the OJ data set which is part of the ISLR package.

    (a) Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.

        ```{r}
        training_and_testing_data <- split_data_set_into_training_and_testing_data(
            OJ,
            number_of_training_data = 800
        )
        training_data <- training_and_testing_data$training_data
        testing_data <- training_and_testing_data$testing_data
        ```

    (b) Fit a tree to the training data, with Purchase as the response and the other variables as predictors. Use the `summary()` function to produce summary statistics about the tree, and describe the results obtained. What is the training error rate? How many terminal nodes does the tree have?

        ```{r}
        full_tree <- tree(Purchase ~ ., data = training_data)
        summary(full_tree)
        ```
        
        Our full tree is a classification tree that predicts whether a customer will purchase Citrus Hill or Minute Maid orange juice. A tree is grown by binary recursive partitioning using the response in the specified formula, $Purchase$, and choosing splits from the terms of the right-hand-side, which in our case are all terms besides $Purchase$. The predictors actually used in tree construction are $LoyalCH$, $SalePriceMM$, $SpecialCH$, $PriceDiff$, and $STORE$. $Purchase$ is a factor with levels $CH$ and $MM$ indicating whether the customer purchased Citrus Hill or Minute Maid Orange Juice. $LoyalCH$ seems to be a rate of customer brand loyalty for CH between $0$ and $1$. $SalePriceMM$ seems to be the net sale price of Minute Maid orange juice in dollars. $SpecialCH$ seems to be an indicator of whether or not there is a special on Citrus Hill orange juice. $PriceDiff$ seems to be net sale price of Minute Maid orange juice less net sale price of Citrus Hill orange juice in dollars. $STORE$ seems to be a categorical variable indicating at which of $5$ possible stores the purchase occurred. In our full tree there are $9$ terminal nodes / leaves. The deviance of our full tree is $564.7$. A small deviance indicates a tree that provides a good fit to the training data. The residual mean deviance for our full tree is $564.7 / (800 - 9)$. The training error rate / misclassification error rate for our full tree is $126 / 800$.

    (c) Type in the name of the tree object in order to get a detailed text output. Pick one of the terminal nodes, and interpret the information displayed.
    
        ```{r}
        full_tree
        ```
        
        A terminal node / leaf / branch to leaf is indicated by an asterisk. Because `full_tree` outputs information for each of two branches for each internal node / node other than the root node / trunk and the leaves, we speak in terms of branches. Let us consider the terminal node / leaf / branch to leaf labeled $4$. The prediction of the full tree associated with this branch to leaf is $MM$. We arrive at this branch when the split criterion $LoyalCH$ is less than $0.504$ and less than $0.282$. The split criterion associated with this branch is $LoyalCH < 0.282$. The number of observations / purchases in our training data set is $800$. Of those purchases, $341$ purchases are by customers with loyalty to Citrus Hill less than $0.504$. Of those purchases, $167$ purchases are by customers with loyalty to Citrus Hill less than $0.282$. The number of purchases associated with our branch is $167$ with a deviance of $114.2$. $0.108$ of purchases associated with our branch were of Citrus Hill orange juice. $0.892$ of purchases associated with our branch were of Minute Maid orange juice.

    (d) Create a plot of the tree, and interpret the results.
    
        ```{r, fig.width = 14, fig.height = 10}
        plot(full_tree)
        text(full_tree, pretty = 0)
        ```
        
        Per our full tree, the most important predictor of whether a customer will purchase Citrus Hill or Minute Maid orange juice is loyalty to Citrus Hill. The split criterion for the first non-root / internal node / the first pair of branches is $LoyalCH$. The split criteria for the second internal node in the second echelon is also $LoyalCH$.

    (e) Predict the response on the test data, and produce a confusion matrix comparing the test labels to the predicted test labels. What is the test error rate?

        ```{r}
        vector_of_predicted_purchases <- predict(full_tree, testing_data, type = "class")
        confusion_matrix <- table(vector_of_predicted_purchases, testing_data$Purchase)
        confusion_matrix
        number_of_purchases_of_Citrus_Hill_orange_juice_predicted_correctly <- 144
        number_of_purchases_of_Minute_Maid_orange_juice_predicted_correctly <- 70
        number_of_purchases_predicted_correctly <-
            number_of_purchases_of_Citrus_Hill_orange_juice_predicted_correctly +
            number_of_purchases_of_Minute_Maid_orange_juice_predicted_correctly
        number_of_purchases <- nrow(testing_data)
        test_accuracy <- number_of_purchases_predicted_correctly / number_of_purchases
        test_error_rate <- 1 - test_accuracy
        test_error_rate
        ```
        
        The test error rate is about $0.207$.

(f) Apply the `cv.tree()` function to the training set in order to determine the optimal tree size.

(g) Produce a plot with tree size on the x-axis and cross-validated classification error rate on the y-axis.

(h) Which tree size corresponds to the lowest cross-validated classification error rate?

(i) Produce a pruned tree corresponding to the optimal tree size obtained using cross-validation. If cross-validation does not lead to selection of a pruned tree, then create a pruned tree with five terminal nodes.

(j) Compare the training error rates between the pruned and unpruned trees. Which is higher?

(k) Compare the test error rates between the pruned and unpruned trees. Which is higher?
